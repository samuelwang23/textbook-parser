{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = os.path.join(Path().absolute(), \"Sections\")\n",
    "NUM_CHAPTERS = 23\n",
    "def make_chapter_folders():\n",
    "    os.mkdir(parent)\n",
    "    for chapter_num in range(1, NUM_CHAPTERS + 1):\n",
    "        chapter_string = str(chapter_num)\n",
    "        if chapter_num < 10:\n",
    "            chapter_string = \"0\" + chapter_string\n",
    "        chapter_string = \"ch\" + chapter_string\n",
    "        chapter_path = os.path.join(parent, chapter_string)\n",
    "        os.mkdir(chapter_path)\n",
    "# make_chapter_folders() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats =  {\n",
    " 'Big Picture Questions',\n",
    " 'HISTORIANS’ VOICES',\n",
    " 'Introduction',\n",
    " 'Letter to Changchun',\n",
    " 'MENELIK II',\n",
    " 'Memoirs',\n",
    " 'Namondjok and the Lightning Man',\n",
    " 'Next Steps: For Further Study',\n",
    " 'REFLECTIONS',\n",
    " 'Second Thoughts',\n",
    " 'The History and Description of Africa',\n",
    " 'The Marvelous Races of the East',\n",
    " 'The Rainbow Serpent Awakens',\n",
    " 'WORKING WITH EVIDENCE',\n",
    " 'What’s the Significance?',\n",
    " 'Yhi Brings Life to the World',\n",
    " 'assessment',\n",
    " 'bibliography',\n",
    " 'end-of-section',\n",
    " 'learning-outcomes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skips = [\n",
    " 'What’s the Significance?',\n",
    " 'assessment',\n",
    " 'bibliography',\n",
    " 'end-of-section',\n",
    " 'learning-outcomes', \n",
    " 'Next Steps: For Further Study',\n",
    " 'Second Thoughts',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = [\n",
    "     'WORKING WITH EVIDENCE',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_driver = webdriver.Chrome()\n",
    "def get_text():\n",
    "    text = section_driver.find_element_by_tag_name(\"p\").text + \"\\n\"\n",
    "    for p in section_driver.find_elements_by_class_name(\"indent\"):\n",
    "        text += p.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def get_definitions():\n",
    "    definitions = section_driver.find_elements_by_class_name(\"glossref\")\n",
    "    if len(definitions) < 1:\n",
    "        return []\n",
    "    return [definition.get_attribute(\"href\").split(\"_\")[-1] for definition in definitions]\n",
    "\n",
    "def process_section(contents):\n",
    "    html = open(\"section.html\", 'w', encoding='utf-8')\n",
    "    html.write(contents)\n",
    "    html.close()\n",
    "    section_driver.get(\"file:///C:/Dev/Text%20Summarizer/Textbook%20Scraper/section.html\")\n",
    "    return get_text(), get_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/295135/turn-a-string-into-a-valid-filename\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def slugify(value, allow_unicode=False):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/django/django/blob/master/django/utils/text.py\n",
    "    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n",
    "    dashes to single dashes. Remove characters that aren't alphanumerics,\n",
    "    underscores, or hyphens. Convert to lowercase. Also strip leading and\n",
    "    trailing whitespace, dashes, and underscores.\n",
    "    \"\"\"\n",
    "    value = str(value)\n",
    "    if allow_unicode:\n",
    "        value = unicodedata.normalize('NFKC', value)\n",
    "    else:\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
    "    return re.sub(r'[-\\s]+', '-', value).strip('-_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\".\\HTML\", topdown=False):\n",
    "    for name in files:\n",
    "        path = Path(os.path.join(root, name))\n",
    "        f = open(path)\n",
    "        html = open(\"test.html\", 'w')\n",
    "        text = f.read()\n",
    "        html.write(text)\n",
    "        html.close()\n",
    "        f.close()\n",
    "        driver.get(\"file:///C:/Dev/Text%20Summarizer/Textbook%20Scraper/test.html\")\n",
    "        \n",
    "        driver.execute_script(\"document.querySelectorAll('.semantic-sup').forEach(e => e.remove());\");\n",
    "        sections = driver.find_elements_by_tag_name(\"section\")\n",
    "        \n",
    "        chapter_number = path.parent.name\n",
    "        for section in sections:\n",
    "            if section.get_attribute(\"class\") == \"sect1\":\n",
    "                contents = section.get_attribute(\"innerHTML\").split(\"<section\")[0]\n",
    "            else:\n",
    "                contents = section.get_attribute(\"innerHTML\")\n",
    "            title = section.get_attribute(\"title\")\n",
    "            if title in skips:\n",
    "                continue\n",
    "            if title in breaks:\n",
    "                break\n",
    "            section_path = Path(os.path.join(Path().absolute(), \"Sections\", path.parent.name, slugify(title)+ \".txt\"))\n",
    "            section_file = open(section_path, \"w+\")\n",
    "            text, defintions = process_section(contents)\n",
    "            section_file.write(text)\n",
    "            section_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
